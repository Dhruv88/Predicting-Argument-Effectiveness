{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer, AutoModel\nfrom datasets import Dataset, load_dataset\nfrom glob import glob\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, log_loss\nimport collections\nimport lightgbm\nimport multiprocessing as mp\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"Q_FoblrPuWcg","execution":{"iopub.status.busy":"2022-11-13T12:17:07.342279Z","iopub.execute_input":"2022-11-13T12:17:07.344229Z","iopub.status.idle":"2022-11-13T12:17:13.324070Z","shell.execute_reply.started":"2022-11-13T12:17:07.344120Z","shell.execute_reply":"2022-11-13T12:17:13.323046Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### Loading and Preprocessing of Data","metadata":{"id":"DCvLKayxv3KF"}},{"cell_type":"code","source":"dir = \"../input/feedback-prize-effectiveness\"\nessay_dir_train = dir + \"/train\"\nessay_dir_test = dir + \"/test\"\ntrain = pd.read_csv(dir + \"/train.csv\")\ntest = pd.read_csv(dir + \"/test.csv\")\ntrain_essay_ids = train.essay_id.unique()\ntest_essay_ids = test.essay_id.unique()\ndiscourse_ids = train[\"discourse_id\"].values\n\ndef read_essay_train(essay_id):\n  fname_train = f\"{essay_dir_train}/{essay_id}.txt\"\n  with open(fname_train) as f:\n    lines = f.read() \n  return lines\n\ndef read_essay_test(essay_id):\n  fname_train = f\"{essay_dir_test}/{essay_id}.txt\"\n  with open(fname_train) as f:\n    lines = f.read() \n  return lines\n\ntrain_essays = [read_essay_train(id) for id in train_essay_ids]\ntest_essays = [read_essay_test(id) for id in test_essay_ids]\n\ntrain_essay_map = dict(zip(train_essay_ids, train_essays))\ntest_essay_map = dict(zip(test_essay_ids, test_essays))\n\ntrain[\"essay_text\"] = train.essay_id.map(train_essay_map)\ntest[\"essay_text\"] = test.essay_id.map(test_essay_map)\n\ntrain.head()","metadata":{"id":"fb5dLbldvGxV","outputId":"4f0ebc75-4eb4-4988-c01a-bd6e502f684c","execution":{"iopub.status.busy":"2022-11-13T12:17:13.329649Z","iopub.execute_input":"2022-11-13T12:17:13.330562Z","iopub.status.idle":"2022-11-13T12:17:45.152319Z","shell.execute_reply.started":"2022-11-13T12:17:13.330516Z","shell.execute_reply":"2022-11-13T12:17:45.151413Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   discourse_id      essay_id  \\\n0  0013cc385424  007ACE74B050   \n1  9704a709b505  007ACE74B050   \n2  c22adee811b6  007ACE74B050   \n3  a10d361e54e4  007ACE74B050   \n4  db3e453ec4e2  007ACE74B050   \n\n                                      discourse_text discourse_type  \\\n0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n1  On my perspective, I think that the face is a ...       Position   \n2  I think that the face is a natural landform be...          Claim   \n3  If life was on Mars, we would know by now. The...       Evidence   \n4  People thought that the face was formed by ali...   Counterclaim   \n\n  discourse_effectiveness                                         essay_text  \n0                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n1                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n2                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n3                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n4                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discourse_id</th>\n      <th>essay_id</th>\n      <th>discourse_text</th>\n      <th>discourse_type</th>\n      <th>discourse_effectiveness</th>\n      <th>essay_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013cc385424</td>\n      <td>007ACE74B050</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>Lead</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9704a709b505</td>\n      <td>007ACE74B050</td>\n      <td>On my perspective, I think that the face is a ...</td>\n      <td>Position</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c22adee811b6</td>\n      <td>007ACE74B050</td>\n      <td>I think that the face is a natural landform be...</td>\n      <td>Claim</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a10d361e54e4</td>\n      <td>007ACE74B050</td>\n      <td>If life was on Mars, we would know by now. The...</td>\n      <td>Evidence</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>db3e453ec4e2</td>\n      <td>007ACE74B050</td>\n      <td>People thought that the face was formed by ali...</td>\n      <td>Counterclaim</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-11-13T12:17:45.153681Z","iopub.execute_input":"2022-11-13T12:17:45.154019Z","iopub.status.idle":"2022-11-13T12:17:46.105350Z","shell.execute_reply.started":"2022-11-13T12:17:45.153986Z","shell.execute_reply":"2022-11-13T12:17:46.104246Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb\n","output_type":"stream"}]},{"cell_type":"code","source":"endpoint = \"microsoft/deberta-v3-base\"\n\n# endpoint = \"../input/pppm-deberta-v3-large-baseline-w-w-b-train/config.pth\"\n\n# endpoint =\"../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased\"\n# /deberta-v3-base\"\n# model     = AutoModel.from_pretrained(endpoint)\n# tokenizer = AutoTokenizer.from_pretrained(model_path_or_name)\n\ntokenizer = AutoTokenizer.from_pretrained(endpoint)\n# tokenizer = AutoTokenizer.\nd_types = sorted(train[\"discourse_type\"].unique())\n\nstart_token_ids = []\nend_token_ids = []\n\nfor t in d_types:\n  tokenizer.add_tokens([f\"[START_{t}]\"], special_tokens=True)\n  start_token_ids.append(tokenizer.encode(f\"[START_{t}]\")[1])\nfor t in d_types:\n  tokenizer.add_tokens([f\"[END_{t}]\"], special_tokens=True)\n  end_token_ids.append(tokenizer.encode(f\"[END_{t}]\")[1])\n\ntokenizer.add_tokens([\"\\n\"], special_tokens=True)\nvocab_size = len(tokenizer)","metadata":{"id":"mQdozxWnGgaS","outputId":"1a2f7f3c-76f1-4719-f3cf-19a81520361d","execution":{"iopub.status.busy":"2022-11-13T12:17:46.108760Z","iopub.execute_input":"2022-11-13T12:17:46.109112Z","iopub.status.idle":"2022-11-13T12:17:52.868124Z","shell.execute_reply.started":"2022-11-13T12:17:46.109081Z","shell.execute_reply":"2022-11-13T12:17:52.867159Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0ff62a8d1084d87a2b6bcca25de6102"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83bf3d1c57494ef8b9fcc4180f61fc49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a4382aef653405d8bb6fbf24bf7faee"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"grps_train = train.groupby(\"essay_id\", sort=False)\ngrps_test = test.groupby(\"essay_id\", sort=False)\n\ndef process_essays(grps, mode): \n  processed_texts = []\n  labels_grp = []\n  for grp in grps.groups:\n    g = grps.get_group(grp)\n    t = \"\"\n    if mode == \"train\":\n      labels = g[\"discourse_effectiveness\"].values\n    end = 0\n\n    for j in range(len(g)):\n      d = g[\"discourse_text\"].values[j]\n      t += f\" [START_{g.discourse_type.values[j]}]  \" + d + f\" [END_{g.discourse_type.values[j]}] \"\n    t = \" \".join(g[\"discourse_type\"].values) + f\" [SEP] \" + t\n    processed_texts.append(t)\n    if mode == \"train\":\n      labels_grp.append(labels)\n  if mode == \"train\":\n    return processed_texts, labels_grp\n  else:\n    return processed_texts\nprocessed_essays_train, processed_essays_train_labels = process_essays(grps_train, \"train\")\nprocessed_essays_test = process_essays(grps_test, \"test\")","metadata":{"id":"r0PxK3oJIgo_","execution":{"iopub.status.busy":"2022-11-13T12:17:52.869510Z","iopub.execute_input":"2022-11-13T12:17:52.870211Z","iopub.status.idle":"2022-11-13T12:17:54.975554Z","shell.execute_reply.started":"2022-11-13T12:17:52.870174Z","shell.execute_reply":"2022-11-13T12:17:54.974577Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"processed_essays_train[0]","metadata":{"id":"ucVQQfamLklM","outputId":"d630c828-56c1-4963-c35b-483a31a426ac","execution":{"iopub.status.busy":"2022-11-13T12:17:54.977075Z","iopub.execute_input":"2022-11-13T12:17:54.977454Z","iopub.status.idle":"2022-11-13T12:17:54.983986Z","shell.execute_reply.started":"2022-11-13T12:17:54.977416Z","shell.execute_reply":"2022-11-13T12:17:54.982962Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'Lead Position Claim Evidence Counterclaim Rebuttal Evidence Counterclaim Concluding Statement [SEP]  [START_Lead]  Hi, i\\'m Isaac, i\\'m going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn\\'t know if the landform was created by life on Mars, or if it is just a natural landform.  [END_Lead]  [START_Position]  On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I\\'ll be talking about how I think that is is a natural landform  [END_Position]  [START_Claim]  I think that the face is a natural landform because there is no life on Mars that we have descovered yet  [END_Claim]  [START_Evidence]  If life was on Mars, we would know by now. The reason why I think it is a natural landform because, nobody live on Mars in order to create the figure. It says in paragraph 9, \"It\\'s not easy to target Cydonia,\" in which he is saying that its not easy to know if it is a natural landform at this point. In all that they\\'re saying, its probably a natural landform.  [END_Evidence]  [START_Counterclaim]  People thought that the face was formed by alieans because they thought that there was life on Mars.  [END_Counterclaim]  [START_Rebuttal]  though some say that life on Mars does exist, I think that there is no life on Mars.  [END_Rebuttal]  [START_Evidence]  It says in paragraph 7, on April 5, 1998, Mars Global Surveyor flew over Cydonia for the first time. Michael Malin took a picture of Mars with his Orbiter Camera, that the face was a natural landform.  [END_Evidence]  [START_Counterclaim]  Everyone who thought it was made by alieans even though it wasn\\'t, was not satisfied. I think they were not satisfied because they have thought since 1976 that it was really formed by alieans.  [END_Counterclaim]  [START_Concluding Statement]  Though people were not satified about how the landform was a natural landform, in all, we new that alieans did not form the face. I would like to know how the landform was formed. we know now that life on Mars doesn\\'t exist.  [END_Concluding Statement] '"},"metadata":{}}]},{"cell_type":"code","source":"processed_essays_train_labels[0]","metadata":{"id":"_oCqNJkts1-m","outputId":"6414a867-df9a-438c-973e-a48f5e68acd1","execution":{"iopub.status.busy":"2022-11-13T12:17:54.985223Z","iopub.execute_input":"2022-11-13T12:17:54.985685Z","iopub.status.idle":"2022-11-13T12:17:54.994131Z","shell.execute_reply.started":"2022-11-13T12:17:54.985649Z","shell.execute_reply":"2022-11-13T12:17:54.993135Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array(['Adequate', 'Adequate', 'Adequate', 'Adequate', 'Adequate',\n       'Ineffective', 'Adequate', 'Adequate', 'Adequate'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"def encode(text):\n    sample = dict()\n    encodings = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        padding=\"max_length\",\n        truncation=True,\n        max_length=2048,\n#         max_length=512,\n    )\n    sample[\"input_ids\"] = encodings[\"input_ids\"][0]\n    sample[\"token_type_ids\"] = encodings[\"token_type_ids\"][0]\n    sample[\"attention_mask\"] = encodings[\"attention_mask\"][0]\n\n    return sample\n\nx_train = [encode(essay) for essay in processed_essays_train]\nx_test = [encode(essay) for essay in processed_essays_test]\n\nprint(x_train[0])","metadata":{"id":"UQdRzzREPytZ","outputId":"161e3fe4-dd6c-4ce1-dd5f-f7725ffde0b4","execution":{"iopub.status.busy":"2022-11-13T12:17:54.995694Z","iopub.execute_input":"2022-11-13T12:17:54.996311Z","iopub.status.idle":"2022-11-13T12:18:04.319730Z","shell.execute_reply.started":"2022-11-13T12:17:54.996277Z","shell.execute_reply":"2022-11-13T12:18:04.318578Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([    1,  8380, 18172,  ...,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0,  ..., 0, 0, 0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])}\n","output_type":"stream"}]},{"cell_type":"code","source":"labels_dict = {\"Adequate\": 0, \"Effective\": 1, \"Ineffective\": 2}\n\ny_train = [[labels_dict[label] for label in processed_essays_train_labels[i]] for i in range(len(x_train))]\nx_train[2]","metadata":{"id":"3-5AoGaWSuZK","outputId":"b9f3f87a-609b-4633-b269-1f0cfdfd606c","execution":{"iopub.status.busy":"2022-11-13T12:18:04.321092Z","iopub.execute_input":"2022-11-13T12:18:04.321562Z","iopub.status.idle":"2022-11-13T12:18:04.343377Z","shell.execute_reply.started":"2022-11-13T12:18:04.321525Z","shell.execute_reply":"2022-11-13T12:18:04.342436Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([    1,  8380, 18172,  ...,     0,     0,     0]),\n 'token_type_ids': tensor([0, 0, 0,  ..., 0, 0, 0]),\n 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])}"},"metadata":{}}]},{"cell_type":"code","source":"y_train[2]","metadata":{"id":"RUq4QTWZtONw","outputId":"8f27f5b3-b602-4d09-ebba-682d255e1961","execution":{"iopub.status.busy":"2022-11-13T12:18:04.347898Z","iopub.execute_input":"2022-11-13T12:18:04.348186Z","iopub.status.idle":"2022-11-13T12:18:04.355937Z","shell.execute_reply.started":"2022-11-13T12:18:04.348160Z","shell.execute_reply":"2022-11-13T12:18:04.354452Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[0, 0, 0, 2, 0, 0, 0]"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(len(x_train)):\n  input, attention_mask = x_train[i][\"input_ids\"], x_train[i][\"attention_mask\"]\n  idx = int(torch.where(attention_mask == 1)[0].max())\n  idx += 1\n  input = input[:idx]\n\n\n  idx0 = torch.where(\n  (input >= min(start_token_ids))\n  & (input<= max(start_token_ids))\n      )[0]\n            \n  idx1 = torch.where(\n  (input >= min(end_token_ids))\n  & (input <= max(end_token_ids))\n  )[0]\n\n      \n  if idx0.shape != idx1.shape:\n    print(tokenizer.batch_decode(input))","metadata":{"id":"XIw97xMk3GV3","execution":{"iopub.status.busy":"2022-11-13T12:18:04.357467Z","iopub.execute_input":"2022-11-13T12:18:04.357993Z","iopub.status.idle":"2022-11-13T12:18:04.598535Z","shell.execute_reply.started":"2022-11-13T12:18:04.357957Z","shell.execute_reply":"2022-11-13T12:18:04.597633Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class FeedbackDataset(Dataset):\n    def __init__(self, grp_texts, labels=None, mode=\"train\"):\n        self.grp_texts = grp_texts\n        self.labels = labels\n        self.mode = mode\n\n    def __len__(self):\n        return len(self.grp_texts)\n\n    def __getitem__(self, idx):\n        x = self.grp_texts[idx]\n        if self.mode == \"train\":\n          y = self.labels[idx]\n          return x, y\n        else:\n          return x","metadata":{"id":"J7_mv4u7vvIQ","execution":{"iopub.status.busy":"2022-11-13T12:18:04.600024Z","iopub.execute_input":"2022-11-13T12:18:04.600354Z","iopub.status.idle":"2022-11-13T12:18:04.607787Z","shell.execute_reply.started":"2022-11-13T12:18:04.600321Z","shell.execute_reply":"2022-11-13T12:18:04.606644Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Load Model","metadata":{"id":"HctAANWsv9Yk"}},{"cell_type":"code","source":"backbone = AutoModel.from_pretrained(endpoint)","metadata":{"id":"irdwWHFEUTHy","outputId":"e1a48223-6029-4a02-aa39-4b65d7cebc58","execution":{"iopub.status.busy":"2022-11-13T12:18:04.609356Z","iopub.execute_input":"2022-11-13T12:18:04.610088Z","iopub.status.idle":"2022-11-13T12:18:25.813516Z","shell.execute_reply.started":"2022-11-13T12:18:04.610053Z","shell.execute_reply":"2022-11-13T12:18:25.812292Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76d2879cb4a64c60be3ea374465fd73f"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight']\n- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"print(start_token_ids)\nprint(end_token_ids)\n\nclass Pooling(nn.Module):\n  def __init__(self, start_token_ids, end_token_ids):\n    super().__init__()\n    self.feat_mult = 3\n    self.start_token_ids = start_token_ids\n    self.end_token_ids = end_token_ids\n  \n  def forward(self, x, input, am):\n    out = []\n    for j in range(x.shape[0]):\n      idx0 = torch.where(\n      (input[j] >= min(self.start_token_ids))\n      & (input[j] <= max(self.start_token_ids))\n      )[0]\n            \n      idx1 = torch.where(\n      (input[j] >= min(self.end_token_ids))\n      & (input[j] <= max(self.end_token_ids))\n      )[0]\n\n      xx = []\n      for jj in range(len(idx0)):\n        xx0 = x[j, idx0[jj]]\n        xx1 = x[j, idx1[jj]]\n        xx2temp = x[j, idx0[jj] + 1: idx1[jj]]\n        xx2 = xx2temp.mean(dim=0)\n        xxx = torch.cat([xx0, xx2, xx1]).unsqueeze(0)\n        xx.append(xxx)\n      xx = torch.cat(xx)\n      out.append(xx)\n    return out","metadata":{"id":"HIRb-udAT09a","outputId":"dc116df2-1794-484f-997a-89202fcb3e93","execution":{"iopub.status.busy":"2022-11-13T12:18:25.815195Z","iopub.execute_input":"2022-11-13T12:18:25.816134Z","iopub.status.idle":"2022-11-13T12:18:25.838275Z","shell.execute_reply.started":"2022-11-13T12:18:25.816091Z","shell.execute_reply":"2022-11-13T12:18:25.837235Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[128001, 128002, 128003, 128004, 128005, 128006, 128007]\n[128008, 128009, 128010, 128011, 128012, 128013, 128014]\n","output_type":"stream"}]},{"cell_type":"code","source":"class Model(nn.Module):\n  def __init__(self, vocab_size, num_classes):\n    super().__init__()\n    self.backbone = backbone\n    self.backbone.resize_token_embeddings(vocab_size)\n    self.pooler = Pooling(start_token_ids, end_token_ids)\n    self.classifier = nn.Sequential(\n      nn.Linear(768*3, num_classes, bias=True)\n    )\n  \n  def forward(self, x):\n    idx = int(torch.where(x[\"attention_mask\"] == 1)[1].max())\n    idx += 3\n    attention_mask = x[\"attention_mask\"][:, :idx]\n    input_ids = x[\"input_ids\"][:, :idx]\n    token_type_ids = x[\"token_type_ids\"][:, :idx]\n    x = self.backbone(attention_mask = attention_mask.to(\"cuda\"), input_ids=input_ids.to(\"cuda\"), token_type_ids=token_type_ids.to(\"cuda\"))\n    x = x.last_hidden_state\n    x = self.pooler(x, input_ids, attention_mask)\n    x = torch.cat(x)\n    return self.classifier(x)","metadata":{"id":"EVfuyzlnS_j5","execution":{"iopub.status.busy":"2022-11-13T12:18:25.839654Z","iopub.execute_input":"2022-11-13T12:18:25.840059Z","iopub.status.idle":"2022-11-13T12:18:25.853181Z","shell.execute_reply.started":"2022-11-13T12:18:25.840020Z","shell.execute_reply":"2022-11-13T12:18:25.852261Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{"id":"JJZ8hhXoy-lW"}},{"cell_type":"code","source":"from collections import defaultdict\nfrom torch.optim import AdamW\nfrom transformers import get_scheduler\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\n\nbs, lr = 1, 3e-6\n\nmodel = Model(vocab_size, 3)\nx_train, y_train = np.array(x_train), np.array(y_train)\nx_train, x_eval, y_train, y_eval = train_test_split(x_train, y_train, train_size=0.1,test_size=0.02)\n# x_train, x_eval, y_train, y_eval = train_test_split(x_train, y_train, test_size=0.2)\n\ntrain_ds = FeedbackDataset(x_train, y_train)\neval_ds = FeedbackDataset(x_eval, y_eval)\ntrain_dataloader = DataLoader(train_ds, shuffle=True, batch_size=bs)\neval_dataloader = DataLoader(eval_ds, batch_size=bs)\noptimizer = AdamW(model.parameters(), lr=lr)\nnum_training_steps = 5 * len(train_dataloader)\nlr_scheduler = get_scheduler(\n  name=\"cosine\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n)\nmodel.to(\"cuda\")\nprint(\"Training:\")\nprint(\"------------------------------------------------------\")\nprogress_bar = tqdm(range(num_training_steps))\nloss_fn = nn.CrossEntropyLoss()\nfor epoch in range(5):\n  c_loss = 0\n  count = 0\n  c_accuracy = 0\n\n  model.train()\n  for batch in train_dataloader:\n    count += 1\n    x, y = batch\n    y = torch.Tensor(y)\n    outputs = model(x)\n    y = y.type(torch.LongTensor).to(\"cuda\")\n    loss = loss_fn(outputs, y)\n    acc = accuracy_score(y.to(\"cpu\").detach().numpy(), torch.argmax(F.softmax(outputs), dim=-1).to(\"cpu\").detach().numpy())\n    c_loss += loss\n    c_accuracy += acc\n    loss.backward()\n    optimizer.step()\n    lr_scheduler.step()\n    optimizer.zero_grad()\n    progress_bar.update(1)\n  final_loss_train = c_loss/count\n  final_accuracy_train = c_accuracy/count\n\n  c_loss = 0\n  count = 0\n  c_accuracy = 0\n  print(f\"Training Done for epoch {epoch + 1}\")\n  print(\"------------------------------------------------------\")\n\n  print(\"Evaluating:\")\n  print(\"------------------------------------------------------\")\n  model.eval()\n  for batch in eval_dataloader:\n    with torch.inference_mode():\n      count += 1\n      x, y = batch\n      y = torch.Tensor(y)\n      outputs = model(x)\n      y = y.type(torch.LongTensor).to(\"cuda\")\n      loss = loss_fn(outputs, y)\n      acc = accuracy_score(y.to(\"cpu\").detach().numpy(), torch.argmax(F.softmax(outputs), dim=-1).to(\"cpu\").detach().numpy())\n      c_loss += loss\n      c_accuracy += acc\n  final_loss_eval = c_loss/count\n  final_accuracy_eval = c_accuracy/count\n  print(f\"Loss at epoch on Training Data {epoch + 1} is {final_loss_train}\")\n  print(f\"Accuracy at epoch {epoch + 1} on Training Data is {final_accuracy_train}\")\n  print(f\"Loss at epoch on Test Data {epoch + 1} is {final_loss_eval}\")\n  print(f\"Accuracy at epoch {epoch + 1} on Test Data is {final_accuracy_eval}\")\n  print('''\n------------------------------------------------------\n    \n''')","metadata":{"id":"370N9VjsG74f","outputId":"d0613dbc-6ee0-4e54-b043-01c39bb8165c","execution":{"iopub.status.busy":"2022-11-13T12:18:25.854748Z","iopub.execute_input":"2022-11-13T12:18:25.855144Z","iopub.status.idle":"2022-11-13T12:24:32.880621Z","shell.execute_reply.started":"2022-11-13T12:18:25.855110Z","shell.execute_reply":"2022-11-13T12:24:32.879472Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Training:\n------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2095 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d48893d044940b1968741dad9258d13"}},"metadata":{}},{"name":"stdout","text":"Training Done for epoch 1\n------------------------------------------------------\nEvaluating:\n------------------------------------------------------\nLoss at epoch on Training Data 1 is 0.9142217636108398\nAccuracy at epoch 1 on Training Data is 0.5735354270251406\nLoss at epoch on Test Data 1 is 0.811692476272583\nAccuracy at epoch 1 on Test Data is 0.6271074494288778\n\n------------------------------------------------------\n    \n\nTraining Done for epoch 2\n------------------------------------------------------\nEvaluating:\n------------------------------------------------------\nLoss at epoch on Training Data 2 is 0.7784014940261841\nAccuracy at epoch 2 on Training Data is 0.6574302256199112\nLoss at epoch on Test Data 2 is 0.7840568423271179\nAccuracy at epoch 2 on Test Data is 0.6438611322539893\n\n------------------------------------------------------\n    \n\nTraining Done for epoch 3\n------------------------------------------------------\nEvaluating:\n------------------------------------------------------\nLoss at epoch on Training Data 3 is 0.7180153727531433\nAccuracy at epoch 3 on Training Data is 0.6896959236777614\nLoss at epoch on Test Data 3 is 0.7392330765724182\nAccuracy at epoch 3 on Test Data is 0.6846262203405058\n\n------------------------------------------------------\n    \n\nTraining Done for epoch 4\n------------------------------------------------------\nEvaluating:\n------------------------------------------------------\nLoss at epoch on Training Data 4 is 0.6739928126335144\nAccuracy at epoch 4 on Training Data is 0.706919092548762\nLoss at epoch on Test Data 4 is 0.7463164925575256\nAccuracy at epoch 4 on Test Data is 0.6957378930593213\n\n------------------------------------------------------\n    \n\nTraining Done for epoch 5\n------------------------------------------------------\nEvaluating:\n------------------------------------------------------\nLoss at epoch on Training Data 5 is 0.6614266633987427\nAccuracy at epoch 5 on Training Data is 0.7145106358503288\nLoss at epoch on Test Data 5 is 0.7392025589942932\nAccuracy at epoch 5 on Test Data is 0.6899839248053532\n\n------------------------------------------------------\n    \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Testing and Saving Model","metadata":{"id":"YTUvqTIozD5Z"}},{"cell_type":"code","source":"test_ds = FeedbackDataset(x_test, mode=\"test\")\ntest_dataloader = DataLoader(test_ds, batch_size=1)\n\nmodel.eval()\nfor batch in test_dataloader:\n  with torch.inference_mode():\n    logits = model(batch)\n    probability = F.softmax(logits, dim=-1).to(\"cpu\").detach().numpy()\nprint(probability)","metadata":{"id":"rixVtTwEnn4x","outputId":"4a5697b2-6c57-419e-8cc3-3bcb81319c40","execution":{"iopub.status.busy":"2022-11-13T12:24:32.882226Z","iopub.execute_input":"2022-11-13T12:24:32.882894Z","iopub.status.idle":"2022-11-13T12:24:32.932415Z","shell.execute_reply.started":"2022-11-13T12:24:32.882855Z","shell.execute_reply":"2022-11-13T12:24:32.931345Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[[0.37845686 0.5685745  0.05296867]\n [0.5242642  0.46183833 0.01389746]\n [0.48563904 0.47762066 0.03674033]\n [0.5074369  0.45732632 0.03523682]\n [0.36128938 0.61270213 0.02600852]\n [0.22346056 0.7541404  0.02239905]\n [0.21853067 0.7611354  0.0203339 ]\n [0.26685083 0.7167637  0.01638545]\n [0.2215631  0.7575984  0.02083853]\n [0.27375698 0.69836277 0.02788026]]\n","output_type":"stream"}]},{"cell_type":"code","source":"dir","metadata":{"execution":{"iopub.status.busy":"2022-11-13T12:24:32.933954Z","iopub.execute_input":"2022-11-13T12:24:32.934322Z","iopub.status.idle":"2022-11-13T12:24:32.940722Z","shell.execute_reply.started":"2022-11-13T12:24:32.934285Z","shell.execute_reply":"2022-11-13T12:24:32.939617Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'../input/feedback-prize-effectiveness'"},"metadata":{}}]},{"cell_type":"code","source":"output_numpy=probability","metadata":{"execution":{"iopub.status.busy":"2022-11-13T12:24:32.942557Z","iopub.execute_input":"2022-11-13T12:24:32.942920Z","iopub.status.idle":"2022-11-13T12:24:32.949858Z","shell.execute_reply.started":"2022-11-13T12:24:32.942884Z","shell.execute_reply":"2022-11-13T12:24:32.948625Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/feedback-prize-effectiveness/sample_submission.csv\")\nsub['Ineffective'] = output_numpy[:,2]\nsub['Adequate'] = output_numpy[:,0]\nsub['Effective'] = output_numpy[:,1]\nsub","metadata":{"execution":{"iopub.status.busy":"2022-11-13T12:24:32.951611Z","iopub.execute_input":"2022-11-13T12:24:32.952027Z","iopub.status.idle":"2022-11-13T12:24:32.977227Z","shell.execute_reply.started":"2022-11-13T12:24:32.951991Z","shell.execute_reply":"2022-11-13T12:24:32.976380Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   discourse_id  Ineffective  Adequate  Effective\n0  a261b6e14276     0.052969  0.378457   0.568574\n1  5a88900e7dc1     0.013897  0.524264   0.461838\n2  9790d835736b     0.036740  0.485639   0.477621\n3  75ce6d68b67b     0.035237  0.507437   0.457326\n4  93578d946723     0.026009  0.361289   0.612702\n5  2e214524dbe3     0.022399  0.223461   0.754140\n6  84812fc2ab9f     0.020334  0.218531   0.761135\n7  c668ff840720     0.016385  0.266851   0.716764\n8  739a6d00f44a     0.020839  0.221563   0.757598\n9  bcfae2c9a244     0.027880  0.273757   0.698363","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discourse_id</th>\n      <th>Ineffective</th>\n      <th>Adequate</th>\n      <th>Effective</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a261b6e14276</td>\n      <td>0.052969</td>\n      <td>0.378457</td>\n      <td>0.568574</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5a88900e7dc1</td>\n      <td>0.013897</td>\n      <td>0.524264</td>\n      <td>0.461838</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9790d835736b</td>\n      <td>0.036740</td>\n      <td>0.485639</td>\n      <td>0.477621</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75ce6d68b67b</td>\n      <td>0.035237</td>\n      <td>0.507437</td>\n      <td>0.457326</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93578d946723</td>\n      <td>0.026009</td>\n      <td>0.361289</td>\n      <td>0.612702</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2e214524dbe3</td>\n      <td>0.022399</td>\n      <td>0.223461</td>\n      <td>0.754140</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>84812fc2ab9f</td>\n      <td>0.020334</td>\n      <td>0.218531</td>\n      <td>0.761135</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>c668ff840720</td>\n      <td>0.016385</td>\n      <td>0.266851</td>\n      <td>0.716764</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>739a6d00f44a</td>\n      <td>0.020839</td>\n      <td>0.221563</td>\n      <td>0.757598</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>bcfae2c9a244</td>\n      <td>0.027880</td>\n      <td>0.273757</td>\n      <td>0.698363</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# tokenizer.save_pretrained(\"/content/drive/MyDrive/Kaggle Training Results/Predicting Effective Arguments/result/debertav3base/tokenizer\")\n# torch.save(model, \"/content/drive/MyDrive/Kaggle Training Results/Predicting Effective Arguments/result/debertav3base/model/model.pth\")","metadata":{"id":"0t9ltav0npFM","execution":{"iopub.status.busy":"2022-11-13T12:24:32.978664Z","iopub.execute_input":"2022-11-13T12:24:32.978995Z","iopub.status.idle":"2022-11-13T12:24:32.984472Z","shell.execute_reply.started":"2022-11-13T12:24:32.978961Z","shell.execute_reply":"2022-11-13T12:24:32.983391Z"},"trusted":true},"execution_count":21,"outputs":[]}]}