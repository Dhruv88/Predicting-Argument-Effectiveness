{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## SentenceBERT","metadata":{"id":"DCQ2T4zT5UON"}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:51:32.979297Z","iopub.execute_input":"2022-11-16T16:51:32.979747Z","iopub.status.idle":"2022-11-16T16:51:33.006472Z","shell.execute_reply.started":"2022-11-16T16:51:32.979661Z","shell.execute_reply":"2022-11-16T16:51:33.005101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read csv file train.csv and store it in a variable called train_data\ntrain_data = pd.read_csv('../input/feedback-prize-effectiveness/train.csv')\ntrain_data.head()","metadata":{"id":"TXzfmwFK6cDs","execution":{"iopub.status.busy":"2022-11-16T16:51:33.011024Z","iopub.execute_input":"2022-11-16T16:51:33.013424Z","iopub.status.idle":"2022-11-16T16:51:33.342535Z","shell.execute_reply.started":"2022-11-16T16:51:33.013384Z","shell.execute_reply":"2022-11-16T16:51:33.341424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a list of sentences from the train_data - train_data['discourse_text']\ntrain_sentences = train_data['discourse_text'].tolist()\n\ndiscourse_type = train_data['discourse_type'].tolist()\n# discourse_type","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:51:33.344676Z","iopub.execute_input":"2022-11-16T16:51:33.345395Z","iopub.status.idle":"2022-11-16T16:51:33.358029Z","shell.execute_reply.started":"2022-11-16T16:51:33.345357Z","shell.execute_reply":"2022-11-16T16:51:33.356954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\n\ndef readCSV(filename):\n    rows = []\n    with open(filename, 'r') as file:\n        csvreader = csv.reader(file)\n        header = next(csvreader)\n        for row in csvreader:\n            rows.append(row)\n    return rows","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:51:33.360831Z","iopub.execute_input":"2022-11-16T16:51:33.363764Z","iopub.status.idle":"2022-11-16T16:51:33.372132Z","shell.execute_reply.started":"2022-11-16T16:51:33.363727Z","shell.execute_reply":"2022-11-16T16:51:33.371117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discourses = []\ndis_types = []\ndis_effectiveness = []\nrows = readCSV(\"../input/feedback-prize-effectiveness/train.csv\")\nfor row in rows:\n    if len(row[2])<=510:\n        discourses.append(row[2])\n        dis_types.append(row[3])\n        dis_effectiveness.append(row[4])\n    while len(row[2])>510:\n        temp = row[2][:510]\n        row[2] = row[2][510:]\n        discourses.append(temp)\n        dis_types.append(row[3])\n        dis_effectiveness.append(row[4])\nprint(len(discourses),discourses[0])\nprint(len(dis_types))\nprint(len(dis_effectiveness))","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:51:33.377206Z","iopub.execute_input":"2022-11-16T16:51:33.379660Z","iopub.status.idle":"2022-11-16T16:51:33.793635Z","shell.execute_reply.started":"2022-11-16T16:51:33.379623Z","shell.execute_reply":"2022-11-16T16:51:33.792612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"typeDict = {'Lead':0,'Position':1,'Claim':2,'Counterclaim':3,'Rebuttal':4,'Evidence':5,'Concluding Statement':6}\neffectDict = {'Ineffective':0,'Adequate':1,'Effective':2}","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:51:33.795040Z","iopub.execute_input":"2022-11-16T16:51:33.796125Z","iopub.status.idle":"2022-11-16T16:51:33.802090Z","shell.execute_reply.started":"2022-11-16T16:51:33.796085Z","shell.execute_reply":"2022-11-16T16:51:33.800858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport gensim\nimport torch\nimport transformers as ppb\n# from sent2vec.splitter import *\n\nimport os\nimport re\nimport spacy\n\nROOT_DIR = os.getcwd() \nTEST_DIR = os.path.join(ROOT_DIR, 'test')\nDATA_DIR = os.path.join(TEST_DIR, 'dataset')\n\nROOT_LOCAL = '/Users/pedramataee/'\nROOT_LINUX = '~'\n\nWIKI_PATH = os.path.join(ROOT_LINUX, 'gensim-data/glove-wiki-gigaword-300') \nPRETRAINED_VECTORS_PATH_WIKI = os.path.join(WIKI_PATH, 'glove-wiki-gigaword-300.gz')\n\nFASTTEXT_NEWS_PATH = os.path.join(ROOT_LINUX, 'gensim-data/fasttext-wiki-news-subwords-300') \nPRETRAINED_VECTORS_PATH_FASTTEXT = os.path.join(FASTTEXT_NEWS_PATH, 'fasttext-wiki-news-subwords-300.gz')\n\n# Make sure to download \"en_core_web_sm\" package on your machine.\n# In case, you can run: \"python3 -m spacy download en_core_web_sm\"\nos.environ['LANGUAGE_MODEL_SPACY'] = \"en_core_web_sm\"\n\n\nclass Splitter:\n    def __init__(self):\n        self.words = []\n        self.sentences = []\n        try:\n            self.nlp = spacy.load(os.environ['LANGUAGE_MODEL_SPACY'])\n        except Exception as error:\n            print(f'{error}\\n\\n Install \"en_core_web_sm\" in your environment. '\n                  f'Try running: \"python3 -m spacy download en_core_web_sm\" \\n '\n                  f'or follow instrucions here: https://spacy.io/usage')\n\n    def sent2words(self, sentences, **kwargs):\n        add_stop_words = kwargs.get('add_stop_words', [])\n        remove_stop_words = kwargs.get('remove_stop_words', [])\n\n        for w in add_stop_words:\n            self.nlp.vocab[w].is_stop = True\n        for w in remove_stop_words:\n            self.nlp.vocab[w].is_stop = False\n\n        words = []\n        for sentence in sentences:\n            doc = self.nlp(sentence.lower())\n            words.append([token.lemma_ for token in doc if not token.is_punct | token.is_space | token.is_stop])\n\n        self.words = words\n\n    def text2sents(self, texts):\n        for text in texts:\n            doc = self.nlp(text)\n            span = doc[0:5]\n            sents = list(doc.sents)\n            self.sentences.extend([sent for sent in sents])\n\n    def text2words(self, texts):\n        doc = self.nlp(texts)\n        tokenized_texts = []\n        for w in doc:\n            is_clean = w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num\n            if is_clean:\n                tokenized_texts.append(w.lemma_)\n\n        self.words = tokenized_texts\n\n\ndef sentencizer_by_regex(texts):\n    alphabets = \"([A-Za-z])\"\n    prefixes = r\"(Mr|St|Mrs|Ms|Dr)[.]\"\n    suffixes = r\"(Inc|Ltd|Jr|Sr|Co|etc)\"\n    starters = r\"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n    acronyms = r\"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n    websites = r\"[.](com|net|org|io|gov)\"\n\n    text = \" \" + texts + \"  \"\n    text = text.replace(\"\\n\", \" \")\n    text = re.sub(prefixes, \"\\\\1<prd>\", text)\n    text = re.sub(websites, \"<prd>\\\\1\", text)\n    if \"Ph.D\" in text:\n        text = text.replace(\"Ph.D.\", \"Ph<prd>D<prd>\")\n    text = re.sub(r\"\\s\" + alphabets + \"[.] \", \" \\\\1<prd> \", text)\n    text = re.sub(acronyms + \" \" + starters, \"\\\\1<stop> \\\\2\", text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\", \"\\\\1<prd>\\\\2<prd>\\\\3<prd>\", text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\", \"\\\\1<prd>\\\\2<prd>\", text)\n    text = re.sub(\" \" + suffixes + \"[.] \" + starters, \" \\\\1<stop> \\\\2\", text)\n    text = re.sub(\" \" + suffixes + \"[.]\", \" \\\\1<prd>\", text)\n    text = re.sub(\" \" + alphabets + \"[.]\", \" \\\\1<prd>\", text)\n    if \"”\" in text:\n        text = text.replace(\".”\", \"”.\")\n    if \"\\\"\" in text:\n        text = text.replace(\".\\\"\", \"\\\".\")\n    if \"!\" in text:\n        text = text.replace(\"!\\\"\", \"\\\"!\")\n    if \"?\" in text:\n        text = text.replace(\"?\\\"\", \"\\\"?\")\n    text = text.replace(\".\", \".<stop>\")\n    text = text.replace(\"?\", \"?<stop>\")\n    text = text.replace(\"!\", \"!<stop>\")\n    text = text.replace(\"<prd>\", \".\")\n    sentences = text.split(\"<stop>\")\n    sentences = sentences[:-1]\n    sentences = [s.strip() for s in sentences]\n    return sentences\n\nclass Vectorizer:\n    \"\"\"\n    pretrained_weights: str, default='distilbert-base-uncased'\n\n        If the string does not include an extension .txt, .gz or .bin, then Bert vectorizer is loaded using the specified weights.\n        Example: pass 'distilbert-base-multilingual-cased' to load Bert base multilingual model.\n\n        To load word2vec vectorizer pass a valid path to the weights file (.txt, .gz or .bin).\n        Example: pass 'glove-wiki-gigaword-300.gz' to load the Wiki vectors (when saved in the same folder you are running the code).\n\n    \n    ensemble_method: str, default='average'\n\n        How word vectors are computed into sentece vectors.\n    \n    \"\"\"\n    def __init__(self, pretrained_weights = 'distilbert-base-uncased',\n                       ensemble_method = 'average'):\n        _, ext = os.path.splitext(pretrained_weights)\n        self.vectors = []\n        if not ext:\n            print(f'Initializing Bert {pretrained_weights}')\n            self.vectorizer = BertVectorizer(pretrained_weights=pretrained_weights)\n        else:\n            print(f'Initializing word2vec with vector path {pretrained_weights}')\n            self.vectorizer = GensimVectorizer(pretrained_weights=pretrained_weights, \n                                               ensemble_method=ensemble_method)\n\n    def run(self, sentences, remove_stop_words = ['not'], add_stop_words = []):\n        # SANITY CHECK\n        assert type(sentences) == list, 'A list must be passed!'\n        for sentence in sentences:\n            if type(sentence) != str:\n                raise TypeError(f'All items must be string type but {sentence} is type {type(sentence)}.')\n        # RUN\n        self.vectorizer._execute(sentences, remove_stop_words=remove_stop_words, add_stop_words=add_stop_words)\n        vectors = self.vectorizer.vectors\n        for idx in range(vectors.shape[0]):\n            self.vectors.append(vectors[idx])\n\n\nclass BaseVectorizer():\n    def __init__(self, **kwargs):\n        self.pretrained_weights = kwargs.get('pretrained_weights')\n        self.ensemble_method = kwargs.get('ensemble_method')\n        self.vectors = []\n    \n    def _load_model(self):\n        pass\n\n    def _execute(self):\n        pass\n\n\nclass BertVectorizer(BaseVectorizer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._load_model()\n    \n    def _load_model(self):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f'Vectorization done on {self.device}')\n        model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel,\n                                                            ppb.DistilBertTokenizer,\n                                                            self.pretrained_weights)\n        self.tokenizer = tokenizer_class.from_pretrained('../input/huggingface-bert/bert-base-uncased',local_files_only = True)\n        self.model = model_class.from_pretrained('../input/huggingface-bert/bert-base-uncased',local_files_only = True)\n    \n    def _execute(self, sentences, **kwargs):\n        model = self.model.to(self.device)\n        model.eval()\n        tokenized = list(map(lambda x: self.tokenizer.encode(x, add_special_tokens=True), sentences))\n        max_len = 0\n        for i in tokenized:\n            if len(i) > max_len:\n                max_len = len(i)\n        padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized])\n        # Move inputs to same device as model\n        input_ids = torch.tensor(np.array(padded)).type(torch.LongTensor).to(self.device)\n        with torch.no_grad():\n            last_hidden_states = model(input_ids)\n        # Move vector results back to cpu if calculation was done on GPU\n        vectors = last_hidden_states[0][:, 0, :].cpu().numpy()\n        self.vectors = vectors\n\nclass GensimVectorizer(BaseVectorizer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._load_model()\n    \n    def _load_model(self):\n        _, file_extension = os.path.splitext(self.pretrained_weights)\n        # Checks if file extension is binary\n        if file_extension == '.bin':\n            self.model = gensim.models.KeyedVectors.load_word2vec_format(self.pretrained_weights, binary=True)\n        elif file_extension == '.txt' or '.gz':\n            self.model = gensim.models.KeyedVectors.load_word2vec_format(self.pretrained_weights)\n        else:\n            raise IOError(f'The file extension {file_extension} is not valid. Word2vec valid formats are \".txt\" and \".bin\".')\n    \n    def _execute(self, sentences, **kwargs):\n        splitter = Splitter()\n        splitter.sent2words(sentences, remove_stop_words=kwargs.get('remove_stop_words'), add_stop_words=kwargs.get('add_stop_words'))\n        words = splitter.words\n        vectors = []\n        for element in words:\n            temp = []\n            for w in element:\n                temp.append(self.model[w])\n            if self.ensemble_method == 'average':\n                element_vec = np.mean(temp, axis=0)\n                try:\n                    vectors = np.vstack([vectors, element_vec])\n                except:\n                    vectors = element_vec\n        self.vectors = vectors\n        ","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:51:33.804134Z","iopub.execute_input":"2022-11-16T16:51:33.804878Z","iopub.status.idle":"2022-11-16T16:51:43.876412Z","shell.execute_reply.started":"2022-11-16T16:51:33.804837Z","shell.execute_reply":"2022-11-16T16:51:43.875479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import logging\nlogging.set_verbosity_error()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:51:43.877681Z","iopub.execute_input":"2022-11-16T16:51:43.878380Z","iopub.status.idle":"2022-11-16T16:51:43.884445Z","shell.execute_reply.started":"2022-11-16T16:51:43.878334Z","shell.execute_reply":"2022-11-16T16:51:43.883270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sent2vec.vectorizer import Vectorizer\nimport numpy as np\n\ndef getVectors(discourses, dis_types):\n    vectorizer = Vectorizer()\n    dis_vectors = []\n    for i in range(0,len(discourses),100):\n        vectorizer.run(discourses[i:min(i+100,len(discourses))], remove_stop_words=[], add_stop_words=[])\n        temp = vectorizer.vectors\n        for t in range(i,min(i+100,len(discourses))):\n            dis_vectors.append(temp[t][:100])\n    dis_vectors = np.array(dis_vectors)\n\n    # concatenate the type[dis_types[i]] and dis_vectors\n    dis_vectors = np.concatenate((np.array([typeDict[dis_types[i]] for i in range(len(dis_types))]).reshape(-1,1),dis_vectors),axis=1)\n        \n\n    print(len(dis_vectors))\n    print(dis_vectors[0])\n    # return dis_vectors\n\n    output = []\n    # make the output as  the one hot encoding of the effectDict[dis_effectiveness[i]]\n    for i in range(len(dis_effectiveness)):\n        temp = [0,0,0]\n        temp[effectDict[dis_effectiveness[i]]] = 1\n        output.append(temp)\n    output = np.array(output)\n    print(len(output))\n    print(output[0])\n    return dis_vectors,output","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:51:43.885751Z","iopub.execute_input":"2022-11-16T16:51:43.886555Z","iopub.status.idle":"2022-11-16T16:51:43.910917Z","shell.execute_reply.started":"2022-11-16T16:51:43.886518Z","shell.execute_reply":"2022-11-16T16:51:43.910072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input, train_output = getVectors(discourses, dis_types)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:51:43.915630Z","iopub.execute_input":"2022-11-16T16:51:43.916637Z","iopub.status.idle":"2022-11-16T16:54:51.826097Z","shell.execute_reply.started":"2022-11-16T16:51:43.916602Z","shell.execute_reply":"2022-11-16T16:54:51.824808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take 80% of the data as training data and 20% as validation data\ntrain_input = train_input[:int(len(train_input)*0.8)]\ntrain_output = train_output[:int(len(train_output)*0.8)]\nval_input = train_input[int(len(train_input)*0.8):]\nval_output = train_output[int(len(train_output)*0.8):]\n\nprint(len(train_input))\nprint(len(train_output))\nprint(len(val_input))\nprint(len(val_output))","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:54:51.828559Z","iopub.execute_input":"2022-11-16T16:54:51.829010Z","iopub.status.idle":"2022-11-16T16:54:51.836572Z","shell.execute_reply.started":"2022-11-16T16:54:51.828951Z","shell.execute_reply":"2022-11-16T16:54:51.835433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_input","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:54:51.838361Z","iopub.execute_input":"2022-11-16T16:54:51.838743Z","iopub.status.idle":"2022-11-16T16:54:51.849896Z","shell.execute_reply.started":"2022-11-16T16:54:51.838707Z","shell.execute_reply":"2022-11-16T16:54:51.848831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_output.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:54:51.851373Z","iopub.execute_input":"2022-11-16T16:54:51.852286Z","iopub.status.idle":"2022-11-16T16:54:51.859092Z","shell.execute_reply.started":"2022-11-16T16:54:51.852241Z","shell.execute_reply":"2022-11-16T16:54:51.858164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# design a tensorflow keras classfication model\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\ntrain_input = np.array(train_input)\ntrain_output = np.array(train_output)\n\n\nmodel = keras.Sequential([\n    layers.Dense(128, activation='relu', input_shape=[101]),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(3, activation='softmax')\n])\n\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n\nhistory = model.fit(train_input, train_output, epochs=5000)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-16T16:54:51.860261Z","iopub.execute_input":"2022-11-16T16:54:51.860902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import logging\n\nlogging.set_verbosity_error()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a submissions.csv file\n# '''\n# discourse_id,Ineffective,Adequate,Effective\n# a261b6e14276,0.2,0.6,0.4\n# 5a88900e7dc1,3.0,6.0,1.0\n# 9790d835736b,1.0,2.0,3.0\n# 75ce6d68b67b,0.33,0.34,0.33\n# 93578d946723,0.01,0.24,0.47\n# 2e214524dbe3,0.2,0.6,0.4\n# 84812fc2ab9f,3.0,6.0,1.0\n# c668ff840720,1.0,2.0,3.0\n# 739a6d00f44a,0.33,0.34,0.33\n# bcfae2c9a244,0.01,0.24,0.47\n# '''\n\ntest_data = pd.read_csv('../input/feedback-prize-effectiveness/test.csv')\ntest_data.head()\n\ntest_sentences = test_data['discourse_text'].tolist()\ntest_sentences[0]\n\ntest_dis_types  = test_data['discourse_type'].tolist()\n\ntest_input,_ = getVectors(test_sentences,test_dis_types)\ntest_input = np.array(test_input)\n\ntest_output = model.predict(test_input)\n# test_output = np.argmax(test_output, axis=1)\nprint(test_output)\n\nimport csv\n\nwith open('submission.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"discourse_id\",\"Ineffective\",\"Adequate\",\"Effective\"])\n    for i in range(len(test_output)):\n#         temp = [0,0,0]\n#         temp[test_output[i]] = 1\n        writer.writerow([test_data['discourse_id'][i],test_output[i][0],test_output[i][1],test_output[i][2]])\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions for the test dataset (20% of train data)","metadata":{}},{"cell_type":"code","source":"# get the prediction for val_input\nval_pred = model.predict(val_input)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = tf.keras.losses.CategoricalCrossentropy()\nprint(f'Loss in test data: {loss.__call__(val_output, val_pred)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make the hot vector of one size (for accuracy calc)\nval_pred = np.argmax(val_pred, axis=1)\nval_output = np.argmax(val_output, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the accuracy of the model\nfrom sklearn.metrics import accuracy_score\nprint(f'Accuracy: {accuracy_score(val_output, val_pred)*100} %')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the confusion matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(val_output, val_pred))\n\n# get the classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(val_output, val_pred))\n\n# get the f1 score\nfrom sklearn.metrics import f1_score\nprint(f1_score(val_output, val_pred, average='macro'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the precision score\nfrom sklearn.metrics import precision_score\nprint(precision_score(val_output, val_pred, average='macro'))\n\n# get the recall score\nfrom sklearn.metrics import recall_score\nprint(recall_score(val_output, val_pred, average='macro'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the confusion matrix\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\narray = confusion_matrix(val_output, val_pred)\ndf_cm = pd.DataFrame(array, index = [i for i in \"012\"],\n                    columns = [i for i in \"012\"])\nplt.figure(figsize = (10,7))\nsn.heatmap(df_cm, annot=True)\n\n# plot the loss and accuracy of the model\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['accuracy'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'g', label='Training loss')\nplt.title('Training loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.figure(figsize=(15,10))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Final value of Loss: {loss[-1]}')\nprint(f'Least value of Loss: {min(loss)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the accuracy of the model during training\nplt.clf()   # clear figure\n\nacc = history.history['accuracy']\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.title('Training accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.figure(figsize=(15,10))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Final value of Accuracy: {acc[-1]}')\nprint(f'Maximum value of Accuracy: {max(acc)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the predicted and actual values of output\nplt.clf()   # clear figure\n\n# plot the val_pred and val_output arrays on the same graph\nplt.plot(val_pred, 'ro', label='val_pred')\nplt.plot(val_output, 'b', label='val_output')\nplt.title('val_pred and val_output')\nplt.xlabel('Epochs')\nplt.ylabel('val_pred and val_output')\nplt.legend()\nplt.figure(figsize=(13,5))\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the val_pred and val_output arrays\nplt.hist(val_pred, bins=3, alpha=0.5, label='val_pred')\nplt.hist(val_output, bins=3, alpha=0.5, label='val_output')\nplt.legend(loc='upper right')\nplt.figure(figsize=(10,5))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}